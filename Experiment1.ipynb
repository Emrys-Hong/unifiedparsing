{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./broden_dataset/ade20k/ADE20K_2016_07_26/index_ade20k.mat\n",
      "break point\n"
     ]
    }
   ],
   "source": [
    "# system libs\n",
    "import os\n",
    "import datetime\n",
    "import argparse\n",
    "from distutils.version import LooseVersion\n",
    "# Numerical libs\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.io import loadmat\n",
    "# Our libs\n",
    "from dataset import TestDataset\n",
    "from models import ModelBuilder, SegmentationModule\n",
    "from utils import colorEncode\n",
    "from lib.nn import user_scattered_collate, async_copy_to\n",
    "from lib.utils import as_numpy, mark_volatile\n",
    "import lib.utils.data as torchdata\n",
    "import cv2\n",
    "from broden_dataset_utils.joint_dataset import broden_dataset\n",
    "from utils import maskrcnn_colorencode, remove_small_mat\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'material': 26, 'object': 336, 'part': 153, 'scene': 365, 'texture': 47}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broden_dataset.nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    arch_decoder = 'upernet'\n",
    "    arch_encoder='resnet50'\n",
    "    batch_size = 1\n",
    "    fc_dim = 2048\n",
    "    gpu_id = 0\n",
    "    imgMaxSize=1000\n",
    "    imgSize=[300, 400, 500, 600]\n",
    "    model_path='upp-resnet50-upernet'\n",
    "    num_class=150\n",
    "    num_val=-1\n",
    "    padding_constant=8\n",
    "    segm_downsampling_rate=8\n",
    "    suffix='_epoch_40.pth'\n",
    "    weights_encoder = '/media/emrys/Samsung_T5/research/unifiedparsing/upp-resnet50-upernet/encoder_epoch_40.pth'\n",
    "    weights_decoder = '/media/emrys/Samsung_T5/research/unifiedparsing/upp-resnet50-upernet/decoder_epoch_40.pth'\n",
    "    nr_classes = broden_dataset.nr.copy()\n",
    "    nr_classes['part'] = sum([len(parts) for obj, parts in broden_dataset.object_part.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open('/media/emrys/Samsung_T5/research/Data/test/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('/media/emrys/Samsung_T5/research/unifiedparsing/infer_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADE_val_00000001.jpg', 'n01443537_22563.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(segmentation_module, loader, args, name):\n",
    "    segmentation_module.eval()\n",
    "    for i, data in enumerate(loader):\n",
    "        # process data\n",
    "        data = data[0]\n",
    "        seg_size = data['img_ori'].shape[0:2]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_ms = {}\n",
    "            for k in ['object', 'material']:\n",
    "                pred_ms[k] = torch.zeros(1, args.nr_classes[k], *seg_size)\n",
    "            pred_ms['part'] = []\n",
    "            for idx_part, object_label in enumerate(broden_dataset.object_with_part):\n",
    "                n_part = len(broden_dataset.object_part[object_label])\n",
    "                pred_ms['part'].append(torch.zeros(1, n_part, *seg_size))\n",
    "            pred_ms['scene'] = torch.zeros(1, args.nr_classes['scene'])\n",
    "\n",
    "            for img in data['img_data']:\n",
    "                # forward pass\n",
    "                feed_dict = async_copy_to({\"img\": img}, args.gpu_id)\n",
    "                pred = segmentation_module(feed_dict, seg_size=seg_size)\n",
    "                for k in ['scene', 'object', 'material']:\n",
    "                    pred_ms[k] = pred_ms[k] + pred[k].cpu() / len(args.imgSize)\n",
    "                for idx_part, object_label in enumerate(broden_dataset.object_with_part):\n",
    "                    pred_ms['part'][idx_part] += pred['part'][idx_part].cpu() / len(args.imgSize)\n",
    "\n",
    "            pred_ms['scene'] = pred_ms['scene'].squeeze(0)\n",
    "            for k in ['object', 'material']:\n",
    "                _, p_max = torch.max(pred_ms[k].cpu(), dim=1)\n",
    "                pred_ms[k] = p_max.squeeze(0)\n",
    "            for idx_part, object_label in enumerate(broden_dataset.object_with_part):\n",
    "                _, p_max = torch.max(pred_ms['part'][idx_part].cpu(), dim=1)\n",
    "                pred_ms['part'][idx_part] = p_max.squeeze(0)\n",
    "\n",
    "            pred_ms = as_numpy(pred_ms)\n",
    "            save_obj(pred_ms, name)\n",
    "        print('[{}] iter {}'\n",
    "              .format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), i))\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    torch.cuda.set_device(args.gpu_id)\n",
    "\n",
    "    # Network Builders\n",
    "    builder = ModelBuilder()\n",
    "    net_encoder = builder.build_encoder(\n",
    "        arch=args.arch_encoder,\n",
    "        fc_dim=args.fc_dim,\n",
    "        weights=args.weights_encoder)\n",
    "    net_decoder = builder.build_decoder(\n",
    "        arch=args.arch_decoder,\n",
    "        fc_dim=args.fc_dim,\n",
    "        nr_classes=args.nr_classes,\n",
    "        weights=args.weights_decoder,\n",
    "        use_softmax=True)\n",
    "    \n",
    "    segmentation_module = SegmentationModule(net_encoder, net_decoder)\n",
    "    segmentation_module.cuda()\n",
    "    \n",
    "    # Dataset and Loader\n",
    "    for file in files:\n",
    "        list_test = [{'fpath_img': '/media/emrys/Samsung_T5/research/unifiedparsing/infer_data/'+file}]\n",
    "        dataset_val = TestDataset(\n",
    "            list_test, args, max_sample=args.num_val)\n",
    "        loader_val = torchdata.DataLoader(\n",
    "            dataset_val,\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=user_scattered_collate,\n",
    "            num_workers=0,\n",
    "            drop_last=True)\n",
    "        \n",
    "        # Main loop\n",
    "        test(segmentation_module, loader_val, args, file.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for net_encoder\n",
      "Loading weights for net_decoder\n",
      "# samples: 1\n",
      "Logcat: save_obj\n",
      "[2018-11-21 00:29:08] iter 0\n",
      "# samples: 1\n",
      "Logcat: save_obj\n",
      "[2018-11-21 00:29:10] iter 0\n"
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
